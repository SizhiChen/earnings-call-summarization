{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Earnings Call Summarization**\n",
    "\n",
    "by Strong Sizhi Chen"
   ],
   "id": "e166cd90243d7cc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:37.778184Z",
     "start_time": "2025-12-08T04:32:36.580274Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"motley-fool-data.pkl\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              date      exchange        q ticker  \\\n",
       "0       Aug 27, 2020, 9:00 p.m. ET  NASDAQ: BILI  2020-Q2   BILI   \n",
       "1       Jul 30, 2020, 4:30 p.m. ET     NYSE: GFF  2020-Q3    GFF   \n",
       "2       Oct 23, 2019, 5:00 p.m. ET  NASDAQ: LRCX  2020-Q1   LRCX   \n",
       "3       Nov 6, 2019, 12:00 p.m. ET  NASDAQ: BBSI  2019-Q3   BBSI   \n",
       "4        Aug 7, 2019, 8:30 a.m. ET  NASDAQ: CSTE  2019-Q2   CSTE   \n",
       "...                            ...           ...      ...    ...   \n",
       "18750    Nov 9, 2021, 1:00 p.m. ET     NYSE: SWX  2021-Q3    SWX   \n",
       "18751  Nov 18, 2021, 12:00 p.m. ET    NYSE: PNNT  2021-Q4   PNNT   \n",
       "18752  Feb 08, 2022, 11:00 a.m. ET     NYSE: TDG  2022-Q1    TDG   \n",
       "18753   Feb 28, 2022, 4:30 p.m. ET  NASDAQ: DVAX  2021-Q4   DVAX   \n",
       "18754   Aug 12, 2021, 9:00 a.m. ET   (NYSE: CIB)  2021-Q2   CIB)   \n",
       "\n",
       "                                              transcript  \n",
       "0      Prepared Remarks:\\nOperator\\nGood day, and wel...  \n",
       "1      Prepared Remarks:\\nOperator\\nThank you for sta...  \n",
       "2      Prepared Remarks:\\nOperator\\nGood day and welc...  \n",
       "3      Prepared Remarks:\\nOperator\\nGood day, everyon...  \n",
       "4      Prepared Remarks:\\nOperator\\nGreetings and wel...  \n",
       "...                                                  ...  \n",
       "18750  Prepared Remarks:\\nOperator\\nLadies and gentle...  \n",
       "18751  Prepared Remarks:\\nOperator\\nGood morning, and...  \n",
       "18752  Prepared Remarks:\\nOperator\\nThank you for sta...  \n",
       "18753  Prepared Remarks:\\nOperator\\nGood day, ladies ...  \n",
       "18754  Prepared Remarks:\\nOperator\\nGood morning, lad...  \n",
       "\n",
       "[18755 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exchange</th>\n",
       "      <th>q</th>\n",
       "      <th>ticker</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aug 27, 2020, 9:00 p.m. ET</td>\n",
       "      <td>NASDAQ: BILI</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>BILI</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, and wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jul 30, 2020, 4:30 p.m. ET</td>\n",
       "      <td>NYSE: GFF</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>GFF</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nThank you for sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct 23, 2019, 5:00 p.m. ET</td>\n",
       "      <td>NASDAQ: LRCX</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>LRCX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day and welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov 6, 2019, 12:00 p.m. ET</td>\n",
       "      <td>NASDAQ: BBSI</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>BBSI</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, everyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aug 7, 2019, 8:30 a.m. ET</td>\n",
       "      <td>NASDAQ: CSTE</td>\n",
       "      <td>2019-Q2</td>\n",
       "      <td>CSTE</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGreetings and wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18750</th>\n",
       "      <td>Nov 9, 2021, 1:00 p.m. ET</td>\n",
       "      <td>NYSE: SWX</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>SWX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nLadies and gentle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18751</th>\n",
       "      <td>Nov 18, 2021, 12:00 p.m. ET</td>\n",
       "      <td>NYSE: PNNT</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>PNNT</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood morning, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18752</th>\n",
       "      <td>Feb 08, 2022, 11:00 a.m. ET</td>\n",
       "      <td>NYSE: TDG</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>TDG</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nThank you for sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18753</th>\n",
       "      <td>Feb 28, 2022, 4:30 p.m. ET</td>\n",
       "      <td>NASDAQ: DVAX</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>DVAX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, ladies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>Aug 12, 2021, 9:00 a.m. ET</td>\n",
       "      <td>(NYSE: CIB)</td>\n",
       "      <td>2021-Q2</td>\n",
       "      <td>CIB)</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood morning, lad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18755 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Clean the Earnings Call**",
   "id": "e7cab25f2dc3c511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:53.157879Z",
     "start_time": "2025-12-08T04:32:37.794729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def is_speaker_line(line: str) -> bool:\n",
    "    line = line.strip()\n",
    "    if line == \"\":\n",
    "        return False\n",
    "\n",
    "    # Pattern 1: \"Name --\"\n",
    "    if re.match(r\"^[A-Za-z][A-Za-z\\s\\.]*\\s--\\s\", line):\n",
    "        return True\n",
    "\n",
    "    # Pattern 2: \"Operator:\", \"Analyst:\", etc.\n",
    "    if re.match(r\"^(Operator|Analyst|Coordinator|Speaker)\\b\", line, re.IGNORECASE):\n",
    "        return True\n",
    "\n",
    "    # Pattern 3: \"Name - Title\"\n",
    "    if re.match(r\"^[A-Za-z][A-Za-z\\s\\.]*\\s-\\s[A-Za-z]\", line):\n",
    "        return True\n",
    "\n",
    "    # Pattern 4: lines ending with \":\" (likely a speaker)\n",
    "    if line.endswith(\":\") and len(line.split()) <= 4:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_disclaimer(line: str) -> bool:\n",
    "    \"\"\" forward-looking statements / safe harbor \"\"\"\n",
    "    text = line.lower()\n",
    "    keywords = [\n",
    "        \"forward-looking statements\",\n",
    "        \"safe harbor\",\n",
    "        \"actual results may differ\",\n",
    "        \"undue reliance\",\n",
    "        \"investors are cautioned\",\n",
    "        \"risk factors\",\n",
    "        \"securities and exchange commission\",\n",
    "    ]\n",
    "    return any(k in text for k in keywords)\n",
    "\n",
    "\n",
    "def is_operator_instruction(line: str) -> bool:\n",
    "    \"\"\" operator instructions \"\"\"\n",
    "    text = line.lower()\n",
    "    patterns = [\n",
    "        \"we will now begin the q&a\",\n",
    "        \"we will now begin the question-and-answer\",\n",
    "        \"please stand by\",\n",
    "        \"your lines are open\",\n",
    "        \"our first question comes from\",\n",
    "        \"we'll now open the call\",\n",
    "        \"this call is being recorded\",\n",
    "        \"a replay will be available\",\n",
    "    ]\n",
    "    return any(p in text for p in patterns)\n",
    "\n",
    "\n",
    "def is_meaningless_short(line: str) -> bool:\n",
    "    \"\"\" remove lines like 'Thanks', 'Good morning', 'Hi everyone' \"\"\"\n",
    "    text = line.strip().lower()\n",
    "\n",
    "    # too short or generic\n",
    "    if len(text) < 8:\n",
    "        return True\n",
    "\n",
    "    keywords = [\n",
    "        \"thank you\",\n",
    "        \"thanks\",\n",
    "        \"good morning\",\n",
    "        \"good afternoon\",\n",
    "        \"good evening\",\n",
    "        \"hi everyone\",\n",
    "        \"hello everyone\",\n",
    "        \"welcome to\",\n",
    "    ]\n",
    "    return any(text.startswith(k) for k in keywords)\n",
    "\n",
    "\n",
    "def is_qa_marker(line: str) -> bool:\n",
    "    text = line.lower()\n",
    "    patterns = [\n",
    "        \"question-and-answer session\",\n",
    "        \"q&a session\",\n",
    "        \"questions and answers\",\n",
    "        \"question and answer session\",\n",
    "    ]\n",
    "    return any(p in text for p in patterns)\n",
    "\n",
    "\n",
    "def clean_transcript(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    cleaned = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line == \"\":\n",
    "            continue\n",
    "\n",
    "        if is_speaker_line(line):\n",
    "            continue\n",
    "        if is_disclaimer(line):\n",
    "            continue\n",
    "        if is_operator_instruction(line):\n",
    "            continue\n",
    "        if is_qa_marker(line):\n",
    "            continue\n",
    "        if is_meaningless_short(line):\n",
    "            continue\n",
    "\n",
    "        cleaned.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned)\n",
    "\n",
    "# Create a new column with cleaned transcripts\n",
    "df[\"clean_transcript\"] = df[\"transcript\"].apply(clean_transcript)"
   ],
   "id": "7b2fcb6a9a55492",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:54.862376Z",
     "start_time": "2025-12-08T04:32:54.859127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect one example before/after\n",
    "idx = 0\n",
    "print(\"===== ORIGINAL TRANSCRIPT (first 500 chars) =====\")\n",
    "print(df.loc[idx, \"transcript\"][:1000], \"\\n\")\n",
    "\n",
    "print(\"===== CLEANED TRANSCRIPT (first 500 chars) =====\")\n",
    "print(df.loc[idx, \"clean_transcript\"][:1000])"
   ],
   "id": "216e128aad3318f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ORIGINAL TRANSCRIPT (first 500 chars) =====\n",
      "Prepared Remarks:\n",
      "Operator\n",
      "Good day, and welcome to the Bilibili 2020 Second Quarter Earnings Conference Call. Today's conference is being recorded.\n",
      "At this time, I would like to turn the conference over to Juliet Yang, Senior Director of Investor Relations. Please go ahead.\n",
      "Juliet Yang -- Senior Director of Investor Relations\n",
      "Thank you, operator.\n",
      "Please note the discussion today will contain forward-looking statements relating to the Company's future performance, and are intended to qualify for the Safe Harbor from liability, as established by the US Private Securities Litigation Reform Act. Such statements are not guarantees of future performance and are subject to certain risks and uncertainties, assumptions and other factors. Some of these risks are beyond the Company's control and could cause actual results to differ materially from those mentioned in today's press release and this discussion. A general discussion of the risk factors that could affect Bilibili's business and finan \n",
      "\n",
      "===== CLEANED TRANSCRIPT (first 500 chars) =====\n",
      "Good day, and welcome to the Bilibili 2020 Second Quarter Earnings Conference Call. Today's conference is being recorded.\n",
      "At this time, I would like to turn the conference over to Juliet Yang, Senior Director of Investor Relations. Please go ahead.\n",
      "During today's call, management will also discuss certain non-GAAP financial measures, for comparison purposes only. For a definition of non-GAAP financial measures and the reconciliation of GAAP to non-GAAP financial results, please see the 2020 second quarter financial results news release issued earlier today.\n",
      "As a reminder, this conference call is being recorded. In addition, an investor presentation and a webcast replay of this conference call will be available on the Bilibili investor relations website at ir.bilibili.com.\n",
      "Joining us today on the call from Bilibili's senior management are Mr. Rui Chen, Chairman of the Board and Chief Executive Officer; Ms. Carly Lee, Vice Chairwoman of the Board and Chief Operating Officer; and Mr. Sam \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TF-IDF Extractive Summarizer**\n",
    "TF-IDF (Term Frequency–Inverse Document Frequency) is a numerical measure used in NLP to evaluate how important a word is within a sentence or document. It combines two ideas: TF, which counts how often a word appears in the current sentence (words appearing more frequently in that sentence are considered more relevant), and IDF, which penalizes words that appear too often across the entire document or corpus (common words like “the”, “and”, “we” get very low scores). By multiplying TF and IDF, TF-IDF assigns high scores to words that are both frequent in a sentence and relatively rare but meaningful globally—such as “revenue”, “margin”, or “cloud” in an earnings call. Because important sentences tend to contain many high-TF-IDF words, TF-IDF can be used for extractive summarization: each sentence is turned into a TF-IDF vector, compared with the document’s overall theme vector, and the most representative sentences are selected as the summary."
   ],
   "id": "a9b279d48dab049c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:55.900116Z",
     "start_time": "2025-12-08T04:32:54.964845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# 1. Simple sentence splitter\n",
    "#    This avoids needing nltk/spacy for now.\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Split a long transcript into sentences using simple regex.\n",
    "    Removes very short or empty sentences.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "\n",
    "    # Split by newline or punctuation + optional whitespace\n",
    "    raw_sents = re.split(r'[\\n\\.!?]+', text)\n",
    "\n",
    "    # Clean whitespace and remove very short sentences\n",
    "    sentences = [s.strip() for s in raw_sents if len(s.strip()) > 20]\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# 2. Extractive summarization function (TF-IDF based)\n",
    "def extractive_summary(text, num_sentences=5):\n",
    "    \"\"\"\n",
    "    Produce an extractive summary by:\n",
    "    1. Splitting transcript into sentences\n",
    "    2. Computing TF-IDF vectors\n",
    "    3. Computing cosine similarity to document vector\n",
    "    4. Selecting top-k sentences\n",
    "    \"\"\"\n",
    "    sentences = split_sentences(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    # TF-IDF for all sentences\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf = vectorizer.fit_transform(sentences)   # sparse matrix\n",
    "\n",
    "    # Document vector (average)\n",
    "    doc_vector = tfidf.mean(axis=0)               # 1 x vocab_size (numpy matrix)\n",
    "\n",
    "    # Convert doc_vector to a proper array\n",
    "    doc_vector = np.asarray(doc_vector)           # shape (1, vocab_size)\n",
    "\n",
    "    # Compute cosine similarity for each sentence vs document vector\n",
    "    scores = cosine_similarity(tfidf, doc_vector).ravel()\n",
    "\n",
    "    # Select the top-k sentences\n",
    "    top_k_idx = np.argsort(scores)[-num_sentences:]\n",
    "    top_k_idx = np.sort(top_k_idx)\n",
    "\n",
    "    selected = [sentences[i]+\".\" for i in top_k_idx]\n",
    "    return \"\\n\".join(selected)"
   ],
   "id": "dca0fcf7000135d0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:56.243491Z",
     "start_time": "2025-12-08T04:32:56.227265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Test extractive summarization on a single transcript\n",
    "sample_text = df.loc[15578, \"clean_transcript\"]\n",
    "\n",
    "print(\"====== ORIGINAL TEXT (first 1000 chars) ======\")\n",
    "print(sample_text[:1000], \"...\\n\")\n",
    "\n",
    "summary = extractive_summary(sample_text, num_sentences=10)\n",
    "\n",
    "print(\"====== EXTRACTIVE SUMMARY ======\")\n",
    "print(summary)"
   ],
   "id": "8decd5f6df332a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ORIGINAL TEXT (first 1000 chars) ======\n",
      "Good day and welcome to the Topgolf Callaway Brands Corp. 2022 third quarter earnings conference call. All participants will be in a listen-only mode. [Operator instructions] After today's presentation, there will be an opportunity to ask questions.\n",
      "[Operator instructions] Please note this event is being recorded. I would now like to turn the conference over to Ms. Lauren Scott, director of investor relations. Please go ahead.\n",
      "Jennifer Thomas, our chief accounting officer; and Patrick Burke, our senior vice president of global finance, are also in the room today for Q&A. Earlier today, the company issued a press release announcing its third quarter 2022 financial results. In addition, there is a presentation that accompanies today's prepared remarks and may make it easier for you to follow the call. This earnings presentation, as well as the earnings release, are both available under the company's investor relations website under the financial results tab.\n",
      "The strength of our results u ...\n",
      "\n",
      "====== EXTRACTIVE SUMMARY ======\n",
      "The strength of our results underscores our leadership position in the Modern Golf ecosystem and the positive trends we're seeing across our business highlighted by increased traffic at our Topgolf venues, market share gains in our golf equipment business, and strong brand momentum in our active lifestyle segment.\n",
      "2022 is clearly going to be another very strong year for us with positive brand momentum and growth across all segments.\n",
      "Even with all of the above, for 2023, we currently expect approximately 10% revenue growth and approximately $600 million in adjusted EBITDA, with Topgolf contributing a little more than half of this EBITDA.\n",
      "At the segment level, Topgolf contributed $414 million in revenue in the quarter, a 24% increase over 2021, reflecting strong same-venue sales growth and additional new venues.\n",
      "5 million in Q3 compared to Q3 2021, but on a constant-currency basis, would have increased.\n",
      "Our inventory balance increased to $722 million at the end of the third quarter of 2022, compared to $385 million at the end of September 30, 2021.\n",
      "For the full year, we expect total capex of approximately $325 million, again, net of REIT reimbursements, including approximately $250 million for Topgolf and $75 million for the non-Topgolf business.\n",
      "Just first, could you just maybe give us a little more color on the 10% revenue growth for next year.\n",
      "The Topgolf business delivered positive traffic growth, as well as price for pretty -- and is building momentum on the same-venue sales side.\n",
      "So not seeing anything right now, but not -- no historical data like we have in the golf equipment business to share with you.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **TextRank baseline**\n",
    "TextRank extractive summarization is a graph-based method for identifying the most important sentences in a document. It works by first splitting the text into individual sentences and computing the similarity between every pair—typically using TF-IDF or sentence embeddings. Each sentence becomes a node in a graph, and the similarity scores become edge weights connecting these nodes. The algorithm then applies PageRank—the same algorithm Google uses to rank web pages—to determine which sentences are most \"central\" or well-connected within the document. Sentences that are similar to many other important sentences receive higher scores. Finally, the top-ranked sentences are selected and arranged in their original order to form an extractive summary. This produces summaries that capture the main ideas by leveraging relationships among sentences rather than relying solely on keyword frequency."
   ],
   "id": "ad76abe512df688d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:56.636183Z",
     "start_time": "2025-12-08T04:32:56.361257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "def textrank_summary(text, num_sentences=5):\n",
    "    \"\"\"\n",
    "    Extractive summarization using a TextRank-like approach:\n",
    "    1. Split transcript into sentences\n",
    "    2. Compute TF-IDF vectors for each sentence\n",
    "    3. Build a sentence similarity graph (cosine similarity)\n",
    "    4. Run PageRank on the graph\n",
    "    5. Select top-k ranked sentences as summary\n",
    "    \"\"\"\n",
    "    sentences = split_sentences(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    # Step 1: TF-IDF for sentences\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Step 2: compute sentence-to-sentence cosine similarity matrix\n",
    "    sim_matrix = cosine_similarity(tfidf, tfidf)\n",
    "\n",
    "    # Step 3: build graph from similarity matrix\n",
    "    # Nodes: sentence indices; Edges: similarity weights\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "\n",
    "    # Step 4: run PageRank\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "\n",
    "    # Step 5: sort sentences by PageRank score\n",
    "    ranked_sentences = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # pick top-k indices\n",
    "    top_indices = [idx for idx, _ in ranked_sentences[:num_sentences]]\n",
    "    top_indices = sorted(top_indices)  # keep original order\n",
    "\n",
    "    selected = [sentences[i] for i in top_indices]\n",
    "    return \"\\n\".join(selected)"
   ],
   "id": "868a58e18cdac0e5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:32:56.713995Z",
     "start_time": "2025-12-08T04:32:56.642069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test on a single cleaned transcript\n",
    "sample_text = df.loc[100, \"clean_transcript\"]\n",
    "\n",
    "print(\"====== ORIGINAL (first 600 chars) ======\")\n",
    "print(sample_text[:1000], \"...\\n\")\n",
    "\n",
    "print(\"====== TF-IDF SUMMARY ======\")\n",
    "print(extractive_summary(sample_text, num_sentences=10), \"\\n\")\n",
    "\n",
    "print(\"====== TEXTRANK SUMMARY ======\")\n",
    "print(textrank_summary(sample_text, num_sentences=10))"
   ],
   "id": "447864764033e00b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ORIGINAL (first 600 chars) ======\n",
      "Neal Froneman\n",
      "Those are our single and most important priorities. I will be assisted in presenting that section by Jevon Martin and Grant Stuart. I'll then do a strategic update, which is titled positioning for positive impact; and I think you will find that very interesting. We do use our year-end results to provide strategic guidance to the market and our shareholders.\n",
      "I will then hand over to Dr. Richard Stewart, our chief operating officer, who will present the results of the operations in detail. As you can see, we've called it operational excellence. We've had an outstanding year considering all the challenges of COVID and safety and so on.\n",
      "Richard will then hand over to our CFO, Charl Keyter, who will then conduct the financial review, which I think you will also enjoy, an outstanding year from a financial perspective as well. And then I'll wrap up with a brief outlook and conclusion. So as I said, let's start with safety. And it gives me absolutely no pleasure to talk about fat ...\n",
      "\n",
      "====== TF-IDF SUMMARY ======\n",
      "8% in our South African PGM operations year on year, this despite an increase in 4% and 15% in tonnes treated at the SA gold and SA PGM operations, respectively.\n",
      "You would also see from these results, and Charl will cover this in more detail, we've declared an additional dividend, but the total dividend for the year will amount to just under ZAR 14 billion or $866 million for the 2021 year.\n",
      "And of course, as I've just mentioned before I handed over to Jevon, we've advanced our green metals strategy with four acquisitions.\n",
      "Total production from these operations amounted to just in excess of 940,000 ounces for the half year and 5% higher than the comparative period the year before, but I think particularly pleasing was the strict control that we maintained over our costs resulted in a nominal 1% lower unit cost year on year.\n",
      "And that was at an average basket price of just over ZAR 40,000 per 4E ounce, marginally higher year on year.\n",
      "This equated to a free cash flow out of these operations for the second half of the year of just over ZAR 8.\n",
      "The production out of these operations was approximately 270,000 ounces for the second half of the year, which was about 11% lower than the comparative period in the year before.\n",
      "environment, together with the need to bring in higher contractors to supplement skill shortages that we're suffering in the area, all resulted in a year on year 18% increase in unit costs to just over $1,000 per ounce for the year and just under $1,040 for the second half.\n",
      "Capital at our PGM operations is marginally higher at ZAR 4.\n",
      "A write-down or impairment of our SA gold assets of just over ZAR 5 billion was recognized at year end. \n",
      "\n",
      "====== TEXTRANK SUMMARY ======\n",
      "8% in our South African PGM operations year on year, this despite an increase in 4% and 15% in tonnes treated at the SA gold and SA PGM operations, respectively\n",
      "You would also see from these results, and Charl will cover this in more detail, we've declared an additional dividend, but the total dividend for the year will amount to just under ZAR 14 billion or $866 million for the 2021 year\n",
      "And of course, as I've just mentioned before I handed over to Jevon, we've advanced our green metals strategy with four acquisitions\n",
      "Total production from these operations amounted to just in excess of 940,000 ounces for the half year and 5% higher than the comparative period the year before, but I think particularly pleasing was the strict control that we maintained over our costs resulted in a nominal 1% lower unit cost year on year\n",
      "And that was at an average basket price of just over ZAR 40,000 per 4E ounce, marginally higher year on year\n",
      "This equated to a free cash flow out of these operations for the second half of the year of just over ZAR 8\n",
      "The production out of these operations was approximately 270,000 ounces for the second half of the year, which was about 11% lower than the comparative period in the year before\n",
      "environment, together with the need to bring in higher contractors to supplement skill shortages that we're suffering in the area, all resulted in a year on year 18% increase in unit costs to just over $1,000 per ounce for the year and just under $1,040 for the second half\n",
      "Capital at our PGM operations is marginally higher at ZAR 4\n",
      "A write-down or impairment of our SA gold assets of just over ZAR 5 billion was recognized at year end\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:46:13.480143Z",
     "start_time": "2025-12-08T04:32:56.718273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add TF-IDF summary for all rows\n",
    "df[\"tfidf_summary\"] = df[\"clean_transcript\"].apply(\n",
    "    lambda t: extractive_summary(t, num_sentences=50)\n",
    ")\n",
    "\n",
    "# Add TextRank summary for all rows\n",
    "df[\"textrank_summary\"] = df[\"clean_transcript\"].apply(\n",
    "    lambda t: textrank_summary(t, num_sentences=50)\n",
    ")"
   ],
   "id": "50619c2efee6dea8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:46:27.328169Z",
     "start_time": "2025-12-08T04:46:13.509929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save it\n",
    "# Or save to CSV (larger file, but easy to inspect)\n",
    "df.to_csv(\"motley_fool_with_summaries.csv\", index=False)"
   ],
   "id": "1c0f72f6383b1faa",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:46:41.777846Z",
     "start_time": "2025-12-08T04:46:27.342162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"motley_fool_with_summaries.csv\")\n",
    "df = df.drop_duplicates(subset=[\"tfidf_summary\"])\n",
    "df"
   ],
   "id": "a5120fcd68e5c16a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              date      exchange        q ticker  \\\n",
       "0       Aug 27, 2020, 9:00 p.m. ET  NASDAQ: BILI  2020-Q2   BILI   \n",
       "1       Jul 30, 2020, 4:30 p.m. ET     NYSE: GFF  2020-Q3    GFF   \n",
       "2       Oct 23, 2019, 5:00 p.m. ET  NASDAQ: LRCX  2020-Q1   LRCX   \n",
       "3       Nov 6, 2019, 12:00 p.m. ET  NASDAQ: BBSI  2019-Q3   BBSI   \n",
       "4        Aug 7, 2019, 8:30 a.m. ET  NASDAQ: CSTE  2019-Q2   CSTE   \n",
       "...                            ...           ...      ...    ...   \n",
       "18750    Nov 9, 2021, 1:00 p.m. ET     NYSE: SWX  2021-Q3    SWX   \n",
       "18751  Nov 18, 2021, 12:00 p.m. ET    NYSE: PNNT  2021-Q4   PNNT   \n",
       "18752  Feb 08, 2022, 11:00 a.m. ET     NYSE: TDG  2022-Q1    TDG   \n",
       "18753   Feb 28, 2022, 4:30 p.m. ET  NASDAQ: DVAX  2021-Q4   DVAX   \n",
       "18754   Aug 12, 2021, 9:00 a.m. ET   (NYSE: CIB)  2021-Q2   CIB)   \n",
       "\n",
       "                                              transcript  \\\n",
       "0      Prepared Remarks:\\nOperator\\nGood day, and wel...   \n",
       "1      Prepared Remarks:\\nOperator\\nThank you for sta...   \n",
       "2      Prepared Remarks:\\nOperator\\nGood day and welc...   \n",
       "3      Prepared Remarks:\\nOperator\\nGood day, everyon...   \n",
       "4      Prepared Remarks:\\nOperator\\nGreetings and wel...   \n",
       "...                                                  ...   \n",
       "18750  Prepared Remarks:\\nOperator\\nLadies and gentle...   \n",
       "18751  Prepared Remarks:\\nOperator\\nGood morning, and...   \n",
       "18752  Prepared Remarks:\\nOperator\\nThank you for sta...   \n",
       "18753  Prepared Remarks:\\nOperator\\nGood day, ladies ...   \n",
       "18754  Prepared Remarks:\\nOperator\\nGood morning, lad...   \n",
       "\n",
       "                                        clean_transcript  \\\n",
       "0      Good day, and welcome to the Bilibili 2020 Sec...   \n",
       "1      Finally, some of today's remarks will adjust f...   \n",
       "2      Good day and welcome to the September 2019 Qua...   \n",
       "3      Good day, everyone and thank you for participa...   \n",
       "4      Greetings and welcome to the Caesarstone Limit...   \n",
       "...                                                  ...   \n",
       "18750  I would now like to turn the conference over t...   \n",
       "18751  Mr. Penn, please go ahead.\\nAt this time, I'd ...   \n",
       "18752  About 90% of our net sales are generated by pr...   \n",
       "18753  Good day, ladies and gentlemen, and welcome to...   \n",
       "18754  Consequently, there are factors that could cau...   \n",
       "\n",
       "                                           tfidf_summary  \\\n",
       "0      The second quarter was another strong quarter ...   \n",
       "1      Adjusted EBITDA increased 31% and adjusted ear...   \n",
       "2      During today's call, we will share our overvie...   \n",
       "3      The third quarter of 2019 had one more work da...   \n",
       "4      We are managing a global growth acceleration p...   \n",
       "...                                                  ...   \n",
       "18750  Karen, will cover recent customer growth, liqu...   \n",
       "18751  These dividend payments highlight the value of...   \n",
       "18752  In our business, we saw another quarter of seq...   \n",
       "18753  Importantly, we expect to continue to grow rev...   \n",
       "18754  Provision charges for the quarter was COP626 b...   \n",
       "\n",
       "                                        textrank_summary  \n",
       "0      Good day, and welcome to the Bilibili 2020 Sec...  \n",
       "1      Adjusted EBITDA increased 31% and adjusted ear...  \n",
       "2      During today's call, we will share our overvie...  \n",
       "3      Good day, everyone and thank you for participa...  \n",
       "4      We are managing a global growth acceleration p...  \n",
       "...                                                  ...  \n",
       "18750  Karen, will cover recent customer growth, liqu...  \n",
       "18751  These dividend payments highlight the value of...  \n",
       "18752  In our business, we saw another quarter of seq...  \n",
       "18753  Importantly, we expect to continue to grow rev...  \n",
       "18754  Provision charges for the quarter was COP626 b...  \n",
       "\n",
       "[17549 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exchange</th>\n",
       "      <th>q</th>\n",
       "      <th>ticker</th>\n",
       "      <th>transcript</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>tfidf_summary</th>\n",
       "      <th>textrank_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aug 27, 2020, 9:00 p.m. ET</td>\n",
       "      <td>NASDAQ: BILI</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>BILI</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, and wel...</td>\n",
       "      <td>Good day, and welcome to the Bilibili 2020 Sec...</td>\n",
       "      <td>The second quarter was another strong quarter ...</td>\n",
       "      <td>Good day, and welcome to the Bilibili 2020 Sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jul 30, 2020, 4:30 p.m. ET</td>\n",
       "      <td>NYSE: GFF</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>GFF</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nThank you for sta...</td>\n",
       "      <td>Finally, some of today's remarks will adjust f...</td>\n",
       "      <td>Adjusted EBITDA increased 31% and adjusted ear...</td>\n",
       "      <td>Adjusted EBITDA increased 31% and adjusted ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oct 23, 2019, 5:00 p.m. ET</td>\n",
       "      <td>NASDAQ: LRCX</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>LRCX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day and welc...</td>\n",
       "      <td>Good day and welcome to the September 2019 Qua...</td>\n",
       "      <td>During today's call, we will share our overvie...</td>\n",
       "      <td>During today's call, we will share our overvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov 6, 2019, 12:00 p.m. ET</td>\n",
       "      <td>NASDAQ: BBSI</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>BBSI</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, everyon...</td>\n",
       "      <td>Good day, everyone and thank you for participa...</td>\n",
       "      <td>The third quarter of 2019 had one more work da...</td>\n",
       "      <td>Good day, everyone and thank you for participa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aug 7, 2019, 8:30 a.m. ET</td>\n",
       "      <td>NASDAQ: CSTE</td>\n",
       "      <td>2019-Q2</td>\n",
       "      <td>CSTE</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGreetings and wel...</td>\n",
       "      <td>Greetings and welcome to the Caesarstone Limit...</td>\n",
       "      <td>We are managing a global growth acceleration p...</td>\n",
       "      <td>We are managing a global growth acceleration p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18750</th>\n",
       "      <td>Nov 9, 2021, 1:00 p.m. ET</td>\n",
       "      <td>NYSE: SWX</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>SWX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nLadies and gentle...</td>\n",
       "      <td>I would now like to turn the conference over t...</td>\n",
       "      <td>Karen, will cover recent customer growth, liqu...</td>\n",
       "      <td>Karen, will cover recent customer growth, liqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18751</th>\n",
       "      <td>Nov 18, 2021, 12:00 p.m. ET</td>\n",
       "      <td>NYSE: PNNT</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>PNNT</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood morning, and...</td>\n",
       "      <td>Mr. Penn, please go ahead.\\nAt this time, I'd ...</td>\n",
       "      <td>These dividend payments highlight the value of...</td>\n",
       "      <td>These dividend payments highlight the value of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18752</th>\n",
       "      <td>Feb 08, 2022, 11:00 a.m. ET</td>\n",
       "      <td>NYSE: TDG</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>TDG</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nThank you for sta...</td>\n",
       "      <td>About 90% of our net sales are generated by pr...</td>\n",
       "      <td>In our business, we saw another quarter of seq...</td>\n",
       "      <td>In our business, we saw another quarter of seq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18753</th>\n",
       "      <td>Feb 28, 2022, 4:30 p.m. ET</td>\n",
       "      <td>NASDAQ: DVAX</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>DVAX</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood day, ladies ...</td>\n",
       "      <td>Good day, ladies and gentlemen, and welcome to...</td>\n",
       "      <td>Importantly, we expect to continue to grow rev...</td>\n",
       "      <td>Importantly, we expect to continue to grow rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18754</th>\n",
       "      <td>Aug 12, 2021, 9:00 a.m. ET</td>\n",
       "      <td>(NYSE: CIB)</td>\n",
       "      <td>2021-Q2</td>\n",
       "      <td>CIB)</td>\n",
       "      <td>Prepared Remarks:\\nOperator\\nGood morning, lad...</td>\n",
       "      <td>Consequently, there are factors that could cau...</td>\n",
       "      <td>Provision charges for the quarter was COP626 b...</td>\n",
       "      <td>Provision charges for the quarter was COP626 b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17549 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:46:41.888575Z",
     "start_time": "2025-12-08T04:46:41.883598Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "4cd6681aa896477",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'exchange', 'q', 'ticker', 'transcript', 'clean_transcript',\n",
       "       'tfidf_summary', 'textrank_summary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:46:46.992305Z",
     "start_time": "2025-12-08T04:46:42.003608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AbstractiveSummarizer:\n",
    "    \"\"\"\n",
    "    Abstractive summarization for earnings call transcripts\n",
    "    Takes extractive summary (10 sentences) as input and generates fluent summary\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"facebook/bart-large-cnn\"):\n",
    "        \"\"\"\n",
    "        Initialize the abstractive summarizer\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name\n",
    "                - \"facebook/bart-large-cnn\" (recommended for general summaries)\n",
    "                - \"google/pegasus-cnn_dailymail\" (good for news-style summaries)\n",
    "                - \"facebook/bart-large-xsum\" (shorter, more abstractive)\n",
    "                - \"allenai/led-large-16384\" (for very long texts)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to('cuda')\n",
    "\n",
    "    def summarize(self, text, max_length=150, min_length=50,\n",
    "                  num_beams=4, length_penalty=2.0,\n",
    "                  no_repeat_ngram_size=3):\n",
    "        \"\"\"\n",
    "        Generate abstractive summary from extractive summary\n",
    "\n",
    "        Args:\n",
    "            text: Input text (typically 10 sentences from extractive summary)\n",
    "            max_length: Maximum length of generated summary\n",
    "            min_length: Minimum length of generated summary\n",
    "            num_beams: Number of beams for beam search (higher = better quality but slower)\n",
    "            length_penalty: Penalty for length (>1.0 encourages longer summaries)\n",
    "            no_repeat_ngram_size: Prevent repetition of n-grams\n",
    "\n",
    "        Returns:\n",
    "            Generated summary text\n",
    "        \"\"\"\n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=1024,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.to('cuda')\n",
    "\n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            summary_ids = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                num_beams=num_beams,\n",
    "                length_penalty=length_penalty,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=no_repeat_ngram_size\n",
    "            )\n",
    "\n",
    "        # Decode summary\n",
    "        summary = self.tokenizer.decode(\n",
    "            summary_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def batch_summarize(self, texts, batch_size=4, **kwargs):\n",
    "        \"\"\"\n",
    "        Summarize multiple texts in batches\n",
    "\n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "            batch_size: Number of texts to process at once\n",
    "            **kwargs: Additional arguments for summarize()\n",
    "\n",
    "        Returns:\n",
    "            List of summaries\n",
    "        \"\"\"\n",
    "        summaries = []\n",
    "\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating summaries\"):\n",
    "            batch = texts[i:i+batch_size]\n",
    "\n",
    "            for text in batch:\n",
    "                summary = self.summarize(text, **kwargs)\n",
    "                summaries.append(summary)\n",
    "\n",
    "        return summaries\n",
    "\n",
    "\n",
    "def compare_models(extractive_summary):\n",
    "    \"\"\"\n",
    "    Compare different models on the same extractive summary\n",
    "    Helps you choose the best model for your use case\n",
    "\n",
    "    Args:\n",
    "        extractive_summary: Input text (10 sentences from extractive method)\n",
    "    \"\"\"\n",
    "    models = [\n",
    "        \"facebook/bart-large-cnn\",\n",
    "        \"google/pegasus-cnn_dailymail\",\n",
    "        \"facebook/bart-large-xsum\",\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print('='*70)\n",
    "\n",
    "        try:\n",
    "            summarizer = AbstractiveSummarizer(model_name)\n",
    "            summary = summarizer.summarize(\n",
    "                extractive_summary,\n",
    "                max_length=130,\n",
    "                min_length=40,\n",
    "                num_beams=4\n",
    "            )\n",
    "\n",
    "            results[model_name] = summary\n",
    "            print(f\"\\nSummary:\\n{summary}\\n\")\n",
    "            print(f\"Length: {len(summary.split())} words\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {model_name}: {str(e)}\")\n",
    "            results[model_name] = None\n",
    "\n",
    "    return results\n",
    "\n",
    "# Configuration presets for different use cases\n",
    "SUMMARY_CONFIGS = {\n",
    "    \"short\": {\n",
    "        \"max_length\": 100,\n",
    "        \"min_length\": 30,\n",
    "        \"num_beams\": 4,\n",
    "        \"length_penalty\": 1.5,\n",
    "        \"no_repeat_ngram_size\": 3\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"max_length\": 150,\n",
    "        \"min_length\": 50,\n",
    "        \"num_beams\": 4,\n",
    "        \"length_penalty\": 2.0,\n",
    "        \"no_repeat_ngram_size\": 3\n",
    "    },\n",
    "    \"long\": {\n",
    "        \"max_length\": 300,\n",
    "        \"min_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"length_penalty\": 2.0,\n",
    "        \"no_repeat_ngram_size\": 3\n",
    "    }\n",
    "}"
   ],
   "id": "d4d200674d3615aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chens\\Desktop\\CS\\6120 NLP\\Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:47:03.977125Z",
     "start_time": "2025-12-08T04:46:47.325929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize abstractive summarizer\n",
    "summarizer = AbstractiveSummarizer(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Process a single example first\n",
    "sample_transcript = df.iloc[0]['transcript']\n",
    "\n",
    "# Step 1: Your extractive summarization (you already have this)\n",
    "extractive_summary1 = extractive_summary(sample_transcript, num_sentences=50)\n",
    "\n",
    "# Step 2: Abstractive summarization\n",
    "abstractive_summary = summarizer.summarize(\n",
    "    extractive_summary1,  # Your 10 sentences\n",
    "    **SUMMARY_CONFIGS[\"long\"]\n",
    ")\n",
    "\n",
    "print(\"Extractive Summary:\")\n",
    "print(extractive_summary1)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "print(\"Abstractive Summary (fluent paragraph):\")\n",
    "print(abstractive_summary)"
   ],
   "id": "fcac92b7a995d3da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive Summary:\n",
      "Good day, and welcome to the Bilibili 2020 Second Quarter Earnings Conference Call.\n",
      "The second quarter was another strong quarter of growth for Bilibili.\n",
      "For the second quarter, MAUs were 172 million, up 55% and DAUs were up 52% to 51 million, both on a year-over-year basis.\n",
      "7% from the same period last year.\n",
      "9 million content creators uploading 6 million videos per month, representing increases of 123% and 148%, respectively, both year-over-year.\n",
      "In the first half of 2020, the number of content creators who submitted their first video creation trial grew by 139% year-over-year.\n",
      "2 billion, up 97% year-over-year.\n",
      "By the end of the second quarter, we had 89 million official members who passed our 100-question exam, up 65% year-over-year.\n",
      "Revenues from our mobile games business were up 36% year-over-year to RMB1.\n",
      "[Foreign Speech] to our game portfolio.\n",
      "These included simulation game Dark Boom, [Foreign Speech], a self-developed ACG game; [Foreign Speech], a highly anticipated title adapted from our self-owned Chinese anime IP; and, several high-quality ACG titles, [Foreign Speech] and [Foreign Speech].\n",
      "Revenues from VAS increased by 153% year-over-year, reaching RMB825 million in the second quarter.\n",
      "5 million premium members, up 100% year-over-year.\n",
      "As for our advertising business, our growing user base and increased brand awareness make Bilibili a must go-to platform for advertisers.\n",
      "Our total net revenues increased by 70% year-over-year to RMB2.\n",
      "The average number of monthly paying users increased by 105% year-over-year, reaching 12.\n",
      "9 million in the second quarter.\n",
      "Cost of revenues increased by 57% year-over-year to RMB2 billion.\n",
      "Selling and marketing expenses were RMB675 million, representing a 181% increase year-over-year.\n",
      "G&A expenses were RMB208 million, representing a 48% increase year-over-year.\n",
      "R&D expenses were RMB331 million, representing a 53% increase year-over-year.\n",
      "Net loss was RMB571 million for the second quarter of 2020, compared to RMB315 million in the same period of 2019.\n",
      "[Foreign Speech] My first question is regarding the user growth.\n",
      "First half, the user growth is very strong.\n",
      "May I know -- can you share with us the quality and retention and the user profile of the new user growth in first half and about the second half growth and also next year, what is the key focuses of your strategy of user growth.\n",
      "How are you going to balance the user retention and maintain the fast user growth in second half of next year.\n",
      "Last year, we have reinforced and reaffirmed user growth will be our key strategic focus and we have been carrying out the strategy efficiently going through the first half of this year, and have made very positive progress.\n",
      "[Foreign Speech] And notably, we've noticed that the new user who come in during the first half of 2020 and also paid for our services within the same period, the ratio has significantly increased compared to the same period last year.\n",
      "[Foreign Speech] So here we also wanted to emphasize the methodology of our user growth.\n",
      "[Foreign Speech] I'll update you the schedule of our user growth plan.\n",
      "[Foreign Speech] I would also update you with our brand -- branding campaigns.\n",
      "[Foreign Speech] And the reason why we want to emphasize on branding campaign is based on our business model, we use content to attract user and community to retain user.\n",
      "As our content continues to evolve to reach broader audiences, one important step, too, is to allow more people to know that Bilibili have so much content to offer, which are in line with our new brand slogan Bilibili-All the Videos You Like.\n",
      "And in the second half, our main focus will be on to convert people from recognizing Bilibili brand to turning to Bilibili users.\n",
      "And we -- during the second half, the marketing campaign were [Phonetic] surrounded our key activity around the key time slots, such as the summer vacation and returning to school, as well as the League of Legends World Championship and our New Year's Eve Gala and many work-like scenario among young generation and to create new content, new brand campaigns and further drive our user growth.\n",
      "My question is actually regarding your game business, which is quite solid in the second quarter.\n",
      "[Foreign Speech] And for games like Princess Connect.\n",
      "[Foreign Speech] As for our game -- overall game business, currently, we have over 30 games in our pipeline.\n",
      "And those games are not only ACG titles, we have been actively expanding our content offerings across different genres since last year, and we've made a quite good progress on some of the console games, indie games and have received good results.\n",
      "Our ad revenue growth actually accelerated on a year-over-year basis from -- in the second quarter.\n",
      "[Foreign Speech] So Bilibili has a video platform, we are one of the biggest beneficiary in the overall videolization industry trend.\n",
      "[Foreign Speech] So during the second quarter, we didn't make any singular marketing campaign toward certain verticals, but rather emphasizing our overall marketing solutions, as well as Bilibili's brand propositions and influence.\n",
      "[Foreign Speech] So as our content verticals expansion, we are quite confident to also expand our advertisers in those verticals.\n",
      "[Foreign Speech] So the Sparkle [Phonetic] platform is a new platform we launched to help our content creators to connect with brand advertisers.\n",
      "[Foreign Speech] Live broadcasting business is, as we mentioned earlier, has always been a part of our content ecosystem.\n",
      "Bilibili's business, live broadcasting business is quite different from other singular live broadcasting platform.\n",
      "[Foreign Speech] Our content offering on the live broadcasting business is actually mirroring what we have to offer on the video platform.\n",
      "[Foreign Speech] So you may have seen on our platform, a lot of the popular live broadcasting hosts are also our top popular top content creators.\n",
      "[Foreign Speech] So compared to other live broadcasting platforms, you're right about the revenue trajectory, we tend to have more stable growth instead of a sharply increased circle because their platform might pursuing [Phonetic] the signing top content host, which will drive the revenue in a short-term.\n",
      "[Foreign Speech] We're quite confident to become the best platform for video content creators, given that the video equals live broadcasting content on our platform, we're also quite confident that will become one of the most popular live broadcasting platform in the future.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Abstractive Summary (fluent paragraph):\n",
      "The second quarter was another strong quarter of growth for Bilibili. MAUs were 172 million, up 55% and DAUs were up 52% to 51 million. Revenues from our mobile games business were up 36% year-over-year to RMB1.2 billion. The number of content creators who submitted their first video creation trial grew by 139% in the first half of 2020. The average number of monthly paying users increased by 105% to 12.9 million. The net loss was RMB571 million for the second quarter of 2020, compared with RMB315 million in the same period of 2019.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T04:47:20.310641Z",
     "start_time": "2025-12-08T04:47:04.048478Z"
    }
   },
   "cell_type": "code",
   "source": "compare_models(extractive_summary1)",
   "id": "a8b56df42dff1c19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Model: facebook/bart-large-cnn\n",
      "======================================================================\n",
      "\n",
      "Summary:\n",
      "The second quarter was another strong quarter of growth for Bilibili. MAUs were 172 million, up 55% and DAUs were up 52% to 51 million. Revenues from our mobile games business were up 36% year-over-year to RMB1.2 billion.\n",
      "\n",
      "Length: 38 words\n",
      "\n",
      "======================================================================\n",
      "Model: google/pegasus-cnn_dailymail\n",
      "======================================================================\n",
      "Error with google/pegasus-cnn_dailymail: \n",
      " requires the protobuf library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Model: facebook/bart-large-xsum\n",
      "======================================================================\n",
      "\n",
      "Summary:\n",
      "Good afternoon, and welcome to the Bilibili 2020 Second Quarter Earnings Conference Call, which is being webcast live on the company's website and mobile app, and will be available for replay on our website and social media platforms.\n",
      "\n",
      "Length: 38 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'facebook/bart-large-cnn': 'The second quarter was another strong quarter of growth for Bilibili. MAUs were 172 million, up 55% and DAUs were up 52% to 51 million. Revenues from our mobile games business were up 36% year-over-year to RMB1.2 billion.',\n",
       " 'google/pegasus-cnn_dailymail': None,\n",
       " 'facebook/bart-large-xsum': \"Good afternoon, and welcome to the Bilibili 2020 Second Quarter Earnings Conference Call, which is being webcast live on the company's website and mobile app, and will be available for replay on our website and social media platforms.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-09T07:21:26.839751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Don't try this one too slow\n",
    "summarizer = AbstractiveSummarizer(\"facebook/bart-large-cnn\")\n",
    "\n",
    "def run_abstractive_summary(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        summary = summarizer.summarize(\n",
    "            text,\n",
    "            **SUMMARY_CONFIGS[\"long\"]\n",
    "        )\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return \"\"\n",
    "\n",
    "df_small = df.iloc[:50].copy()\n",
    "\n",
    "df_small[\"abstractive_summary\"] = df_small[\"tfidf_summary\"].apply(run_abstractive_summary)\n",
    "df_small"
   ],
   "id": "177dc21539489b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4855edea4e556c2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
